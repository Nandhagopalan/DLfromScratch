{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.constant(1,name='x')\n",
    "y=tf.constant(2,name='y')\n",
    "a=tf.constant(3,name='a')\n",
    "b=tf.constant(4,name='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1=tf.multiply(x,y,name='prod1')\n",
    "prod2=tf.multiply(a,b,name='prod2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumtensor=tf.add(prod1,prod2,name='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    writer=tf.summary.FileWriter(logdir='./graphs',graph=sess.graph)\n",
    "    print(sess.run(sumtensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"data/mnist\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of images in training set (55000, 784)\n",
      "No of labels in training set (55000, 10)\n",
      "No of images in test set (10000, 784)\n",
      "No of labels in test set (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"No of images in training set {}\".format(mnist.train.images.shape))\n",
    "print(\"No of labels in training set {}\".format(mnist.train.labels.shape))\n",
    "\n",
    "print(\"No of images in test set {}\".format(mnist.test.images.shape))\n",
    "print(\"No of labels in test set {}\".format(mnist.test.labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc36138c780>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img1 = mnist.train.images[0].reshape(28,28)\n",
    "plt.imshow(img1, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of neurons in input layer\n",
    "num_input = 784  \n",
    "\n",
    "#number of neurons in hidden layer 1\n",
    "num_hidden1 = 512  \n",
    "\n",
    "#number of neurons in hidden layer 2\n",
    "num_hidden2 = 256  \n",
    "\n",
    "#number of neurons in hidden layer 3\n",
    "num_hidden_3 = 128  \n",
    "\n",
    "#number of neurons in output layer\n",
    "num_output = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('input'):\n",
    "    X = tf.placeholder(\"float\", [None, num_input])\n",
    "\n",
    "with tf.name_scope('output'):\n",
    "    Y = tf.placeholder(\"float\", [None, num_output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('weights'):\n",
    "    \n",
    "        weights = {\n",
    "        'w1': tf.Variable(tf.truncated_normal([num_input, num_hidden1], stddev=0.1),name='weight_1'),\n",
    "        'w2': tf.Variable(tf.truncated_normal([num_hidden1, num_hidden2], stddev=0.1),name='weight_2'),\n",
    "        'w3': tf.Variable(tf.truncated_normal([num_hidden2, num_hidden_3], stddev=0.1),name='weight_3'),\n",
    "        'out': tf.Variable(tf.truncated_normal([num_hidden_3, num_output], stddev=0.1),name='weight_4'),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('biases'):\n",
    "\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.constant(0.1, shape=[num_hidden1]),name='bias_1'),\n",
    "        'b2': tf.Variable(tf.constant(0.1, shape=[num_hidden2]),name='bias_2'),\n",
    "        'b3': tf.Variable(tf.constant(0.1, shape=[num_hidden_3]),name='bias_3'),\n",
    "        'out': tf.Variable(tf.constant(0.1, shape=[num_output]),name='bias_4')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Model'):\n",
    "    \n",
    "    with tf.name_scope('layer1'):\n",
    "        layer_1 = tf.nn.relu(tf.add(tf.matmul(X, weights['w1']), biases['b1']) )   \n",
    "    \n",
    "    with tf.name_scope('layer2'):\n",
    "        layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, weights['w2']), biases['b2']))\n",
    "        \n",
    "    with tf.name_scope('layer3'):\n",
    "        layer_3 = tf.nn.relu(tf.add(tf.matmul(layer_2, weights['w3']), biases['b3']))\n",
    "        \n",
    "    with tf.name_scope('output_layer'):\n",
    "         y_hat = tf.nn.sigmoid(tf.matmul(layer_3, weights['out']) + biases['out'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Loss'):\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_hat,labels=Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Accuracy'):\n",
    "    \n",
    "    predicted_digit = tf.argmax(y_hat, 1)\n",
    "    actual_digit = tf.argmax(Y, 1)\n",
    "    \n",
    "    correct_pred = tf.equal(predicted_digit,actual_digit)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Loss_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "\n",
    "tf.summary.scalar(\"Loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_iterations = 5000\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss: 2.272928237915039, Accuracy: 0.125\n",
      "Iteration: 100, Loss: 1.746715784072876, Accuracy: 0.8125\n",
      "Iteration: 200, Loss: 1.6443393230438232, Accuracy: 0.8828125\n",
      "Iteration: 300, Loss: 1.5753722190856934, Accuracy: 0.9296875\n",
      "Iteration: 400, Loss: 1.5484236478805542, Accuracy: 0.9296875\n",
      "Iteration: 500, Loss: 1.567568063735962, Accuracy: 0.90625\n",
      "Iteration: 600, Loss: 1.5653436183929443, Accuracy: 0.8984375\n",
      "Iteration: 700, Loss: 1.5457651615142822, Accuracy: 0.9375\n",
      "Iteration: 800, Loss: 1.5617979764938354, Accuracy: 0.90625\n",
      "Iteration: 900, Loss: 1.5407490730285645, Accuracy: 0.921875\n",
      "Iteration: 1000, Loss: 1.5328903198242188, Accuracy: 0.9453125\n",
      "Iteration: 1100, Loss: 1.5075762271881104, Accuracy: 0.96875\n",
      "Iteration: 1200, Loss: 1.5373607873916626, Accuracy: 0.9296875\n",
      "Iteration: 1300, Loss: 1.5170516967773438, Accuracy: 0.9609375\n",
      "Iteration: 1400, Loss: 1.5117862224578857, Accuracy: 0.9453125\n",
      "Iteration: 1500, Loss: 1.501216173171997, Accuracy: 0.96875\n",
      "Iteration: 1600, Loss: 1.487644076347351, Accuracy: 0.9921875\n",
      "Iteration: 1700, Loss: 1.5018213987350464, Accuracy: 0.96875\n",
      "Iteration: 1800, Loss: 1.5093104839324951, Accuracy: 0.96875\n",
      "Iteration: 1900, Loss: 1.502215027809143, Accuracy: 0.96875\n",
      "Iteration: 2000, Loss: 1.5148046016693115, Accuracy: 0.9453125\n",
      "Iteration: 2100, Loss: 1.5107390880584717, Accuracy: 0.9296875\n",
      "Iteration: 2200, Loss: 1.4959468841552734, Accuracy: 0.9765625\n",
      "Iteration: 2300, Loss: 1.5245203971862793, Accuracy: 0.9453125\n",
      "Iteration: 2400, Loss: 1.4811675548553467, Accuracy: 0.9921875\n",
      "Iteration: 2500, Loss: 1.4810757637023926, Accuracy: 0.9921875\n",
      "Iteration: 2600, Loss: 1.497703194618225, Accuracy: 0.96875\n",
      "Iteration: 2700, Loss: 1.4969916343688965, Accuracy: 0.9453125\n",
      "Iteration: 2800, Loss: 1.5001132488250732, Accuracy: 0.9609375\n",
      "Iteration: 2900, Loss: 1.4834274053573608, Accuracy: 0.96875\n",
      "Iteration: 3000, Loss: 1.4834067821502686, Accuracy: 0.9765625\n",
      "Iteration: 3100, Loss: 1.5037099123001099, Accuracy: 0.9453125\n",
      "Iteration: 3200, Loss: 1.4940593242645264, Accuracy: 0.96875\n",
      "Iteration: 3300, Loss: 1.4997708797454834, Accuracy: 0.96875\n",
      "Iteration: 3400, Loss: 1.4839160442352295, Accuracy: 0.96875\n",
      "Iteration: 3500, Loss: 1.4819064140319824, Accuracy: 0.9765625\n",
      "Iteration: 3600, Loss: 1.4723281860351562, Accuracy: 0.9921875\n",
      "Iteration: 3700, Loss: 1.4945380687713623, Accuracy: 0.9609375\n",
      "Iteration: 3800, Loss: 1.496293306350708, Accuracy: 0.96875\n",
      "Iteration: 3900, Loss: 1.4859631061553955, Accuracy: 0.96875\n",
      "Iteration: 4000, Loss: 1.490959644317627, Accuracy: 0.96875\n",
      "Iteration: 4100, Loss: 1.4902582168579102, Accuracy: 0.9609375\n",
      "Iteration: 4200, Loss: 1.5001249313354492, Accuracy: 0.953125\n",
      "Iteration: 4300, Loss: 1.493650197982788, Accuracy: 0.96875\n",
      "Iteration: 4400, Loss: 1.482496738433838, Accuracy: 0.9609375\n",
      "Iteration: 4500, Loss: 1.4822779893875122, Accuracy: 0.96875\n",
      "Iteration: 4600, Loss: 1.4933435916900635, Accuracy: 0.9765625\n",
      "Iteration: 4700, Loss: 1.4778032302856445, Accuracy: 0.9921875\n",
      "Iteration: 4800, Loss: 1.4921674728393555, Accuracy: 0.96875\n",
      "Iteration: 4900, Loss: 1.4725825786590576, Accuracy: 0.9921875\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    #run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    #save the event files\n",
    "    summary_writer = tf.summary.FileWriter('./graphs', graph=tf.get_default_graph())\n",
    "\n",
    "    #train for some n number of iterations\n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        #get batch of data according to batch size\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        #train the network\n",
    "        sess.run(optimizer, feed_dict={\n",
    "            X: batch_x, Y: batch_y\n",
    "            })\n",
    "\n",
    "        #print loss and accuracy on every 100th iteration\n",
    "        if i % 100 == 0:\n",
    "            \n",
    "            #compute loss, accuracy and summary\n",
    "            batch_loss, batch_accuracy,summary = sess.run(\n",
    "                [loss, accuracy, merge_summary], feed_dict={X: batch_x, Y: batch_y}\n",
    "                )\n",
    "\n",
    "            #store all the summaries\n",
    "            summary_writer.add_summary(summary, i)\n",
    "\n",
    "\n",
    "            print('Iteration: {}, Loss: {}, Accuracy: {}'.format(i,batch_loss,batch_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
