{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "MJa9com018IA",
        "colab_type": "code",
        "outputId": "4824d4dc-9f25-41ba-aca8-c3518d71766f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pyprind\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import pyprind\n",
        "import pickle\n",
        "from string import punctuation\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyprind\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/30/e76fb0c45da8aef49ea8d2a90d4e7a6877b45894c25f12fb961f009a891e/PyPrind-2.11.2-py3-none-any.whl\n",
            "Installing collected packages: pyprind\n",
            "Successfully installed pyprind-2.11.2\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "_yaoyzTR2Gzn",
        "colab_type": "code",
        "outputId": "1de4894d-4c9d-48d6-a9ae-9fa9e7f73849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('movie_data.csv')\n",
        "print(df.head(3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                              review  sentiment\n",
            "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
            "1  OK... so... I really like Kris Kristofferson a...          0\n",
            "2  ***SPOILER*** Do not read this, if you think a...          0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-jnZK63HwM_H",
        "colab_type": "code",
        "outputId": "44c7f90f-1bc3-45f2-ddc0-5f6fcb5998ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.mean([len(rev) for rev in df['review']])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1310.1078649933743"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "pW6JJ5-m4TSI",
        "colab_type": "code",
        "outputId": "657dbd50-29e7-42f5-91f5-b381b47c9f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "## Preprocessing the data:\n",
        "## Separate words and \n",
        "## count each word's occurrence\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "counts = Counter()\n",
        "pbar = pyprind.ProgBar(len(df['review']),\n",
        "                       title='Counting words occurences')\n",
        "\n",
        "for i,review in enumerate(df['review']):\n",
        "   \n",
        "    text = ''.join([c if c not in punctuation else ' '+c+' ' \\\n",
        "                    for c in review]).lower()\n",
        "    \n",
        "    # remove remaining tokens that are not alphabetic\n",
        "    text =' '.join([word for word in text.split() if word.isalpha() and len(word)>2])\n",
        "    \n",
        "    #Remove stopwords\n",
        "    text = ' '.join([w for w in text.split() if not w in stop_words])\n",
        "    \n",
        "    df.loc[i,'review'] = text\n",
        "    pbar.update()\n",
        "    counts.update(text.split())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counting words occurences\n",
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:08:34\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "vYywiz-I48nr",
        "colab_type": "code",
        "outputId": "49ab7a96-0e42-43f7-81b0-107aad72b12f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "## Create a mapping:\n",
        "## Map each unique word to an integer\n",
        "\n",
        "word_counts = sorted(counts, key=counts.get, reverse=True)\n",
        "print(word_counts[:5])\n",
        "word_to_int = {word: i for i, word in enumerate(word_counts, 1)}\n",
        "\n",
        "\n",
        "mapped_reviews = []\n",
        "pbar = pyprind.ProgBar(len(df['review']),\n",
        "                       title='Map reviews to ints')\n",
        "for review in df['review']:\n",
        "    mapped_reviews.append([word_to_int[word] for word in review.split()])\n",
        "    pbar.update()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Map reviews to ints\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['movie', 'film', 'one', 'like', 'good']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:03\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "YeeVoHGM568F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Define fixed-length sequences:\n",
        "## Use the last 1300 elements of each sequence\n",
        "## if sequence length < 1300: left-pad with zeros\n",
        "\n",
        "sequence_length = 1300  ## sequence length (or T in our formulas)\n",
        "\n",
        "sequences = np.zeros((len(mapped_reviews), sequence_length), dtype=int)\n",
        "\n",
        "for i, row in enumerate(mapped_reviews[:1]):\n",
        "    review_arr = np.array(row)\n",
        "    \n",
        "    sequences[i, -len(row):] = review_arr[-sequence_length:]\n",
        "       \n",
        "X_train = sequences[:25000, :]\n",
        "y_train = df.loc[:25000, 'sentiment'].values\n",
        "X_test = sequences[25000:, :]\n",
        "y_test = df.loc[25000:, 'sentiment'].values\n",
        "\n",
        "\n",
        "np.random.seed(123) # for reproducibility\n",
        "\n",
        "## Function to generate minibatches:\n",
        "def create_batch_generator(x, y=None, batch_size=64):\n",
        "    n_batches = len(x)//batch_size\n",
        "    x= x[:n_batches*batch_size]\n",
        "    if y is not None:\n",
        "        y = y[:n_batches*batch_size]\n",
        "    for i in range(0, len(x), batch_size):\n",
        "        if y is not None:\n",
        "            yield x[i:i+batch_size], y[i:i+batch_size]\n",
        "        else:\n",
        "            yield x[i:i+batch_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tYl1ie2GD6sL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SentimentRNN(object):\n",
        "    def __init__(self, n_words, seq_len=200,\n",
        "                 lstm_size=256, num_layers=1, batch_size=64,\n",
        "                 learning_rate=0.0001, embed_size=300):\n",
        "        self.n_words = n_words\n",
        "        self.seq_len = seq_len\n",
        "        self.lstm_size = lstm_size   ## number of hidden units\n",
        "        self.num_layers = num_layers\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.embed_size = embed_size\n",
        "\n",
        "        self.g = tf.Graph()\n",
        "        with self.g.as_default():\n",
        "            tf.set_random_seed(123)\n",
        "            self.build()\n",
        "            self.saver = tf.train.Saver()\n",
        "            self.init_op = tf.global_variables_initializer()\n",
        "           \n",
        "          \n",
        "    def build(self):\n",
        "      \n",
        "        ## Define the placeholders\n",
        "        tf_x = tf.placeholder(tf.int32,\n",
        "                    shape=(self.batch_size, self.seq_len),\n",
        "                    name='tf_x')\n",
        "        tf_y = tf.placeholder(tf.float32,\n",
        "                    shape=(self.batch_size),\n",
        "                    name='tf_y')\n",
        "        tf_keepprob = tf.placeholder(tf.float32,\n",
        "                    name='tf_keepprob')\n",
        "        \n",
        "        ## Create the embedding layer\n",
        "        embedding = tf.Variable(\n",
        "                    tf.random_uniform(\n",
        "                        (self.n_words, self.embed_size),\n",
        "                        minval=-1, maxval=1),\n",
        "                    name='embedding')\n",
        "        embed_x = tf.nn.embedding_lookup(\n",
        "                    embedding, tf_x, \n",
        "                    name='embeded_x')\n",
        "\n",
        "        ## Define LSTM cell and stack them together\n",
        "        cells = tf.contrib.rnn.MultiRNNCell(\n",
        "                [tf.contrib.rnn.DropoutWrapper(\n",
        "                   tf.contrib.rnn.BasicLSTMCell(self.lstm_size),\n",
        "                   output_keep_prob=tf_keepprob)\n",
        "                 for i in range(self.num_layers)])\n",
        "\n",
        "        ## Define the initial state:\n",
        "        self.initial_state = cells.zero_state(\n",
        "                 self.batch_size, tf.float32)\n",
        "        print('  << initial state >> ', self.initial_state)\n",
        "\n",
        "        lstm_outputs, self.final_state = tf.nn.dynamic_rnn(\n",
        "                 cells, embed_x,\n",
        "                 initial_state=self.initial_state)\n",
        "        \n",
        "        ## Note: lstm_outputs shape: \n",
        "        ##  [batch_size, max_time, cells.output_size]\n",
        "        print('\\n  << lstm_output   >> ', lstm_outputs)\n",
        "        print('\\n  << final state   >> ', self.final_state)\n",
        "\n",
        "        ## Apply a FC layer after on top of RNN output:\n",
        "        logits = tf.layers.dense(\n",
        "                 inputs=lstm_outputs[:, -1],\n",
        "                 units=1, activation=None,\n",
        "                 name='logits')\n",
        "        \n",
        "        logits = tf.squeeze(logits, name='logits_squeezed')\n",
        "        print ('\\n  << logits        >> ', logits)\n",
        "        \n",
        "        y_proba = tf.nn.sigmoid(logits, name='probabilities')\n",
        "        \n",
        "        predictions = {\n",
        "            'probabilities': y_proba,\n",
        "            'labels' : tf.cast(tf.round(y_proba), tf.int32,\n",
        "                 name='labels')\n",
        "        }\n",
        "        \n",
        "        print('\\n  << predictions   >> ', predictions)\n",
        "\n",
        "        ## Define the cost function\n",
        "        cost = tf.reduce_mean(\n",
        "                 tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "                 labels=tf_y, logits=logits),\n",
        "                 name='cost')\n",
        "        \n",
        "        ## Define the optimizer\n",
        "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
        "        train_op = optimizer.minimize(cost, name='train_op')\n",
        "        \n",
        "      \n",
        "\n",
        "    def train(self, X_train, y_train, num_epochs):\n",
        "        with tf.Session(graph=self.g) as sess:\n",
        "            sess.run(self.init_op)\n",
        "            iteration = 1\n",
        "            for epoch in range(num_epochs):\n",
        "                state = sess.run(self.initial_state)\n",
        "                \n",
        "                for batch_x, batch_y in create_batch_generator(\n",
        "                            X_train, y_train, self.batch_size):\n",
        "                    feed = {'tf_x:0': batch_x,\n",
        "                            'tf_y:0': batch_y,\n",
        "                            'tf_keepprob:0': 0.5,\n",
        "                            self.initial_state : state}\n",
        "                    loss, _, state = sess.run(\n",
        "                            ['cost:0', 'train_op', \n",
        "                             self.final_state],\n",
        "                            feed_dict=feed)\n",
        "\n",
        "                    if iteration % 20 == 0:\n",
        "                        print(\"Epoch: %d/%d Iteration: %d \"\n",
        "                              \"| Train loss: %.5f\" % (\n",
        "                               epoch + 1, num_epochs,\n",
        "                               iteration, loss))\n",
        "\n",
        "                    iteration +=1\n",
        "                if (epoch+1)%10 == 0:\n",
        "                    self.saver.save(sess,\n",
        "                        \"model/sentiment-%d.ckpt\" % epoch)        \n",
        "     \n",
        "    \n",
        "    def predict(self, X_data, return_proba=False):\n",
        "        preds = []\n",
        "        with tf.Session(graph = self.g) as sess:\n",
        "            self.saver.restore(\n",
        "                sess, tf.train.latest_checkpoint('model/'))\n",
        "            test_state = sess.run(self.initial_state)\n",
        "            for ii, batch_x in enumerate(\n",
        "                create_batch_generator(\n",
        "                    X_data, None, batch_size=self.batch_size), 1):\n",
        "                feed = {'tf_x:0' : batch_x,\n",
        "                        'tf_keepprob:0': 1.0,\n",
        "                        self.initial_state : test_state}\n",
        "                if return_proba:\n",
        "                    pred, test_state = sess.run(\n",
        "                        ['probabilities:0', self.final_state],\n",
        "                        feed_dict=feed)\n",
        "                else:\n",
        "                    pred, test_state = sess.run(\n",
        "                        ['labels:0', self.final_state],\n",
        "                        feed_dict=feed)\n",
        "                    \n",
        "                preds.append(pred)\n",
        "                \n",
        "        return np.concatenate(preds)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k7vpSFI4E0xc",
        "colab_type": "code",
        "outputId": "2d59a20d-3889-4710-c175-e38e35c28522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "cell_type": "code",
      "source": [
        "## Train:\n",
        "\n",
        "n_words = max(list(word_to_int.values())) + 1\n",
        "\n",
        "rnn = SentimentRNN(n_words=n_words, \n",
        "                   seq_len=sequence_length,\n",
        "                   embed_size=256, \n",
        "                   lstm_size=128, \n",
        "                   num_layers=2, \n",
        "                   batch_size=100, \n",
        "                   learning_rate=0.001)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  << initial state >>  (LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros:0' shape=(100, 128) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros_1:0' shape=(100, 128) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/DropoutWrapperZeroState_1/BasicLSTMCellZeroState/zeros:0' shape=(100, 128) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/DropoutWrapperZeroState_1/BasicLSTMCellZeroState/zeros_1:0' shape=(100, 128) dtype=float32>))\n",
            "\n",
            "  << lstm_output   >>  Tensor(\"rnn/transpose_1:0\", shape=(100, 1300, 128), dtype=float32)\n",
            "\n",
            "  << final state   >>  (LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_3:0' shape=(100, 128) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_4:0' shape=(100, 128) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_5:0' shape=(100, 128) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_6:0' shape=(100, 128) dtype=float32>))\n",
            "\n",
            "  << logits        >>  Tensor(\"logits_squeezed:0\", shape=(100,), dtype=float32)\n",
            "\n",
            "  << predictions   >>  {'probabilities': <tf.Tensor 'probabilities:0' shape=(100,) dtype=float32>, 'labels': <tf.Tensor 'labels:0' shape=(100,) dtype=int32>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zK7XfZcJ1L1h",
        "colab_type": "code",
        "outputId": "70b40db0-7ffa-45a7-b659-6b55e008130d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "cell_type": "code",
      "source": [
        "rnn.train(X_train, y_train, num_epochs=40)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/40 Iteration: 20 | Train loss: 0.71428\n",
            "Epoch: 1/40 Iteration: 40 | Train loss: 0.71549\n",
            "Epoch: 1/40 Iteration: 60 | Train loss: 0.68114\n",
            "Epoch: 1/40 Iteration: 80 | Train loss: 0.70194\n",
            "Epoch: 1/40 Iteration: 100 | Train loss: 0.68201\n",
            "Epoch: 1/40 Iteration: 120 | Train loss: 0.70088\n",
            "Epoch: 1/40 Iteration: 140 | Train loss: 0.68353\n",
            "Epoch: 1/40 Iteration: 160 | Train loss: 0.70394\n",
            "Epoch: 1/40 Iteration: 180 | Train loss: 0.68678\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bMASyEqjEcvj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Test: \n",
        "preds = rnn.predict(X_test)\n",
        "y_true = y_test[:len(preds)]\n",
        "print('Test Acc.: %.3f' % (\n",
        "      np.sum(preds == y_true) / len(y_true)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sUEK-L3c1ScR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Get probabilities:\n",
        "proba = rnn.predict(X_test, return_proba=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}